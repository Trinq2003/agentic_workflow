{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configurations\n",
    "from configuration.llm_inference_configuration import APILLMConfiguration\n",
    "from configuration.embedding_inference_configuration import APIEmbeddingModelConfiguration, LocalEmbeddingModelConfiguration\n",
    "from configuration.nlp_configuration import NLPConfiguration\n",
    "from configuration.tool_configuration import ToolConfiguration\n",
    "from configuration.operator_configuration import CoTOperatorConfiguration\n",
    "# System components\n",
    "from llm.azure_openai import AzureOpenAILLM\n",
    "from embedding.local_embedding import LocalEmbeddingModel\n",
    "from embedding.request_embedding import RequestEmbeddingModel\n",
    "from nlp.spacy_nlp import SpacyNLP\n",
    "from tools.python_code_runner import PythonCodeRunnerTool\n",
    "from tools.demonstration_sampling import DemonstrationSamplingTool\n",
    "# Prompt\n",
    "from prompt.zero_shot import ZeroShotPrompt\n",
    "from prompt.few_shot import FewShotPrompt\n",
    "from prompt.user_message import UserMessagePrompt\n",
    "from prompt.assistant_message import AssistantMessagePrompt\n",
    "# Memory\n",
    "from base_classes.memory.memory_atom import AbstractMemoryAtom\n",
    "from base_classes.memory.memory_block import AbstractMemoryBlock\n",
    "from base_classes.memory.memory_topic import AbstractMemoryTopic\n",
    "from base_classes.memory.datatypes.data_item import PromptDataItem\n",
    "from base_classes.memory.memory_worker import MemoryWorker\n",
    "# MCP\n",
    "# from tools.mcp_server\n",
    "# Operator\n",
    "from base_classes.operator import AbstractOperator\n",
    "from operators.cot import CoTOperator\n",
    "from operators.debate import DebateOperator\n",
    "from operators.react import ReactOperator\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s\\t\\t%(levelname)s\\t%(message)s',\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. System component test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. LLM test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Azure OpenAI test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4o_azure_configuration = APILLMConfiguration()\n",
    "gpt_4o_azure_configuration.load(\"configuration/yaml/llm/azure_gpt_4o.yaml\")\n",
    "azure_gpt_4o = AzureOpenAILLM(gpt_4o_azure_configuration)\n",
    "\n",
    "try:\n",
    "    azure_gpt_4o_1 = AzureOpenAILLM(gpt_4o_azure_configuration)\n",
    "except Exception as e:\n",
    "    logging.info(\"LLM unique ID test successful\")\n",
    "    logging.error(f\"Failed to create AzureOpenAILLM instance: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_zero_shot_message = ZeroShotPrompt(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Health check. Say 'hi' to start the conversation.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "sample_zero_shot_message_responses = azure_gpt_4o.query(query=sample_zero_shot_message.prompt, num_responses=2)\n",
    "print(azure_gpt_4o.get_response_texts(sample_zero_shot_message_responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_few_shots_message = FewShotPrompt(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are NetMind assistant. You task is to answer to the user anything about Viettel Group.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Tell me about Viettel Group.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\", \n",
    "            \"content\": \"Viettel Group is a Vietnamese multinational telecommunications company headquartered in Hanoi, Vietnam. It is a state-owned enterprise and operated by the Ministry of Defence. You can find out more about Viettel Group at https://viettel.vn/.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the revenue of Viettel Group? Tell me the list of child companies of Viettel Group?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "sample_few_shots_message_responses = azure_gpt_4o.query(query=sample_few_shots_message.prompt, num_responses=2)\n",
    "print(azure_gpt_4o.get_response_texts(sample_few_shots_message_responses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Embedding test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. Request embedding model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mini_v2_configuration = APIEmbeddingModelConfiguration()\n",
    "all_mini_v2_configuration.load(\"configuration/yaml/embedding/all-MiniLM-L6-v2.yaml\")\n",
    "all_mini_v2 = RequestEmbeddingModel(all_mini_v2_configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mini_v2.encode(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mini_v2 = RequestEmbeddingModel(all_mini_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\"b\": 1, \"c\": 2}\n",
    "list(a.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Tool test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1. Python code runner tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_code_runner_config = ToolConfiguration()\n",
    "python_code_runner_config.load(\"configuration/yaml/tools/python_code_runner.yaml\")\n",
    "python_code_runner = PythonCodeRunnerTool(python_code_runner_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_code_list = [\n",
    "    {\n",
    "        \"code_string\": \"a = 11\\nb = 20\\nresult = a + b\\n\\ndef greet(name):\\n return f'Hello, {name}!'\\n \\nmessage = greet('World')\",\n",
    "        \"id\": \"1\"\n",
    "    },\n",
    "    {\n",
    "        \"code_string\": \"def multiply(x, y):\\n\\treturn x * y\\n\\nnum1 = 5\\nnum2 = 3\\nresult = multiply(num1, num2)\\n\\nprint(f'The product of {num1} and {num2} is {result}.')\",\n",
    "        \"id\": \"2\"\n",
    "    }\n",
    "]\n",
    "\n",
    "results = await python_code_runner.execute(input_code_list=input_code_list)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. NLP model test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1. SpaCy NLP test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_nlp_config = NLPConfiguration()\n",
    "spacy_nlp_config.load(\"configuration/yaml/nlp/spacy.yaml\")\n",
    "spacy_model = SpacyNLP(spacy_nlp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_model.lemmatize(\"Hello, my name is John Doe. I am a software engineer. I love coding and solving problems.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Memory test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Memory Atoms\n",
    "prompt_data_1 = [{\n",
    "    'role': 'user',\n",
    "    'content': 'Calculate the sum of 11 and 20.'\n",
    "}]\n",
    "mem_atom_1 = AbstractMemoryAtom(data=PromptDataItem(UserMessagePrompt(prompt_data_1)))\n",
    "\n",
    "prompt_data_2 = [{\n",
    "    'role': 'assistant',\n",
    "    'content': 'In order to calculate the sum of two numbers, we need to do the following:\\n\\t1. Write a Python code with add_sum() function, receiving 2 variables.\\n\\t2. Execute the code with the given variables.\\n\\t3. Return the result of the sum.'\n",
    "}]\n",
    "mem_atom_2 = AbstractMemoryAtom(data=PromptDataItem(AssistantMessagePrompt(prompt_data_2)))\n",
    "\n",
    "prompt_data_3 = [{\n",
    "    'role': 'assistant',\n",
    "    'content': 'Here is the Python code to calculate the sum of two numbers:\\n\\na = 11\\nb = 20\\nresult = a + b\\n\\nprint(f\"The sum of {a} and {b} is {result}.\")'\n",
    "}]\n",
    "mem_atom_3 = AbstractMemoryAtom(data=PromptDataItem(AssistantMessagePrompt(prompt_data_3)))\n",
    "\n",
    "prompt_data_4 = [{\n",
    "    'role': 'assistant',\n",
    "    'content': 'After executing the code, we got the sum of 11 and 20 is 31.'\n",
    "}]\n",
    "mem_atom_4 = AbstractMemoryAtom(data=PromptDataItem(AssistantMessagePrompt(prompt_data_4)))\n",
    "\n",
    "# Create Memmory Block\n",
    "mem_block = AbstractMemoryBlock()\n",
    "mem_block.add_memory_atom(mem_atom_1)\n",
    "mem_block.add_memory_atom(mem_atom_2)\n",
    "mem_block.add_memory_atom(mem_atom_3)\n",
    "mem_block.add_memory_atom(mem_atom_4)\n",
    "\n",
    "mem_block.mem_atom_graph = {\n",
    "        mem_atom_1.mem_atom_id: [mem_atom_2.mem_atom_id],\n",
    "        mem_atom_2.mem_atom_id: [mem_atom_3.mem_atom_id, mem_atom_4.mem_atom_id],\n",
    "        mem_atom_3.mem_atom_id: [],\n",
    "        mem_atom_4.mem_atom_id: []\n",
    "    }\n",
    "\n",
    "# Create Memory Topic\n",
    "mem_topic = AbstractMemoryTopic()\n",
    "mem_topic.insert_mem_block(mem_block)\n",
    "mem_topic.insert_mem_block(mem_block)\n",
    "mem_topic.insert_mem_block(mem_block)\n",
    "mem_topic.insert_mem_block(mem_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory Worker Initiation\n",
    "spacy_nlp_config = NLPConfiguration()\n",
    "spacy_nlp_config.load(\"configuration/yaml/nlp/spacy.yaml\")\n",
    "spacy_model = SpacyNLP(spacy_nlp_config)\n",
    "\n",
    "gpt_4o_azure_configuration = APILLMConfiguration()\n",
    "gpt_4o_azure_configuration.load(\"configuration/yaml/llm/azure_gpt_4o.yaml\")\n",
    "azure_gpt_4o = AzureOpenAILLM(gpt_4o_azure_configuration)\n",
    "\n",
    "all_mini_v2_configuration = APIEmbeddingModelConfiguration()\n",
    "all_mini_v2_configuration.load(\"configuration/yaml/embedding/all-MiniLM-L6-v2.yaml\")\n",
    "all_mini_v2 = RequestEmbeddingModel(all_mini_v2_configuration)\n",
    "\n",
    "memory_worker = MemoryWorker(\n",
    "    embedding_model=all_mini_v2,\n",
    "    llm=azure_gpt_4o,\n",
    "    nlp_model=spacy_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 07:18:42,070\t\tDEBUG\t[🔧APILLMConfiguration] List of APILLMConfiguration's properties: dict_keys(['llm_id', 'model.model_name', 'model.temperature', 'model.max_tokens', 'cache.enabled', 'cache.cache_expiry', 'llm_api.api_key', 'llm_api.api_base', 'llm_api.api_version', 'llm_api.deployment_name', 'cost.prompt_token_cost', 'cost.response_token_cost', 'retry.max_retries', 'retry.backoff_factor', 'security.encrypted', 'security.trust_strategy'])\n",
      "2025-05-27 07:18:42,070\t\tDEBUG\t[🔧APILLMConfiguration] List of APILLMConfiguration's sensitive properties: []\n",
      "2025-05-27 07:18:42,075\t\tDEBUG\t[🔧AzureOpenAILLM] System Component ID: SYSTEM_COMPONENT | 0 | Component type: <class 'llm.azure_openai.AzureOpenAILLM'>\n",
      "2025-05-27 07:18:42,075\t\tINFO\t[ℹ️AzureOpenAILLM] ✅ LLM config loaded: azure_gpt_4o\n",
      "2025-05-27 07:18:42,079\t\tDEBUG\tStarting new HTTPS connection (1): vtnet-ai-service-swedencentral.cognitiveservices.azure.com:443\n",
      "2025-05-27 07:18:43,644\t\tDEBUG\thttps://vtnet-ai-service-swedencentral.cognitiveservices.azure.com:443 \"POST //openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview HTTP/1.1\" 200 977\n",
      "2025-05-27 07:18:43,648\t\tDEBUG\tload_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2025-05-27 07:18:43,651\t\tDEBUG\tload_verify_locations cafile='C:\\\\Users\\\\ADMIN\\\\miniconda3\\\\Library\\\\ssl\\\\cacert.pem'\n",
      "2025-05-27 07:18:43,987\t\tINFO\t[ℹ️AzureOpenAILLM] ✅ Azure OpenAI model loaded successfully: gpt-4o\n",
      "2025-05-27 07:18:43,992\t\tDEBUG\t[🔧AzureOpenAILLM] LLM ID: LLM | azure_gpt_4o\n",
      "2025-05-27 07:18:43,993\t\tDEBUG\t[🔧ToolConfiguration] List of ToolConfiguration's properties: dict_keys(['tool_id', 'webhook.base_url', 'webhook.webhook_path', 'webhook.method', 'headers.content_type', 'headers.authorization'])\n",
      "2025-05-27 07:18:43,994\t\tDEBUG\t[🔧ToolConfiguration] List of ToolConfiguration's sensitive properties: []\n",
      "2025-05-27 07:18:43,998\t\tDEBUG\t[🔧DemonstrationSamplingTool] System Component ID: SYSTEM_COMPONENT | 1 | Component type: <class 'tools.demonstration_sampling.DemonstrationSamplingTool'>\n",
      "2025-05-27 07:18:43,999\t\tINFO\t[ℹ️DemonstrationSamplingTool] ✅ Tool config loaded: demonstration_sampling\n",
      "2025-05-27 07:18:44,000\t\tDEBUG\t[🔧DemonstrationSamplingTool] Tool ID: TOOL | demonstration_sampling\n"
     ]
    }
   ],
   "source": [
    "gpt_4o_azure_configuration = APILLMConfiguration()\n",
    "gpt_4o_azure_configuration.load(\"configuration/yaml/llm/azure_gpt_4o.yaml\")\n",
    "azure_gpt_4o = AzureOpenAILLM(gpt_4o_azure_configuration)\n",
    "\n",
    "demonstration_sampling_tool_config = ToolConfiguration()\n",
    "demonstration_sampling_tool_config.load(\"configuration/yaml/tools/demonstration_sampling.yaml\")\n",
    "demonstration_sampling_tool = DemonstrationSamplingTool(demonstration_sampling_tool_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 07:18:46,927\t\tDEBUG\t[🔧CoTOperatorConfiguration] List of CoTOperatorConfiguration's properties: dict_keys([])\n",
      "2025-05-27 07:18:46,931\t\tDEBUG\t[🔧CoTOperatorConfiguration] List of CoTOperatorConfiguration's sensitive properties: []\n"
     ]
    }
   ],
   "source": [
    "cot_operator_config = CoTOperatorConfiguration()\n",
    "cot_operator_config.load(\"configuration/yaml/operators/cot.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CoTOperator' object has no attribute 'logger'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cot_operator \u001b[38;5;241m=\u001b[39m CoTOperator(config\u001b[38;5;241m=\u001b[39mcot_operator_config)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Code\\VTNET\\agentic_workflow\\operators\\cot.py:28\u001b[0m, in \u001b[0;36mCoTOperator.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: CoTOperatorConfiguration) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config \u001b[38;5;241m=\u001b[39m config)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_cot_tool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tool_component[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# Only 1 tool component is allowed for CoT operator. This tool is used to construct the CoT prompt.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cot_llm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm_component[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Code\\VTNET\\agentic_workflow\\base_classes\\operator.py:45\u001b[0m, in \u001b[0;36mAbstractOperator.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     43\u001b[0m str_llm_component \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39moperator_llm_component\n\u001b[0;32m     44\u001b[0m list_of_initiated_llm \u001b[38;5;241m=\u001b[39m AbstractLanguageModel\u001b[38;5;241m.\u001b[39mget_llm_ids()\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mList of initiated LLMs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlist_of_initiated_llm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m llm_component \u001b[38;5;129;01min\u001b[39;00m str_llm_component:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m llm_component \u001b[38;5;129;01min\u001b[39;00m list_of_initiated_llm:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CoTOperator' object has no attribute 'logger'"
     ]
    }
   ],
   "source": [
    "cot_operator = CoTOperator(config=cot_operator_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'__module__': 'operators.cot',\n",
       "              '__annotations__': {'_config': configuration.operator_configuration.CoTOperatorConfiguration,\n",
       "               '_construct_cot_tool': tools.demonstration_sampling.DemonstrationSamplingTool,\n",
       "               '_cot_llm': base_classes.llm.AbstractLanguageModel},\n",
       "              '__doc__': '\\n    Inspired by Auto-Cot: Automatic Chain-of-Thought Prompting paper by AWS.\\n    Link: https://arxiv.org/pdf/2210.03493\\n\\n    Args:\\n        AbstractOperator (_type_): _description_\\n    ',\n",
       "              '_config': None,\n",
       "              '_construct_cot_tool': None,\n",
       "              '_cot_llm': None,\n",
       "              '__init__': <function operators.cot.CoTOperator.__init__(self, config: configuration.operator_configuration.CoTOperatorConfiguration) -> None>,\n",
       "              '_demonstration_sampling': <function operators.cot.CoTOperator._demonstration_sampling(self, input_message: Union[prompt.user_message.UserMessagePrompt, prompt.assistant_message.AssistantMessagePrompt]) -> prompt.few_shot.FewShotPrompt>,\n",
       "              'run': <function operators.cot.CoTOperator.run(self, input_message: Union[prompt.user_message.UserMessagePrompt, prompt.assistant_message.AssistantMessagePrompt]) -> prompt.assistant_message.AssistantMessagePrompt>,\n",
       "              '__abstractmethods__': frozenset(),\n",
       "              '_abc_impl': <_abc._abc_data at 0x1cc2a3c6600>})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CoTOperator.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'logger'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m AzureOpenAILLM\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogger\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'logger'"
     ]
    }
   ],
   "source": [
    "AzureOpenAILLM.__dict__['logger']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
