{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configurations\n",
    "from configuration.llm_inference_configuration import APILLMConfiguration\n",
    "from configuration.embedding_inference_configuration import APIEmbeddingModelConfiguration, LocalEmbeddingModelConfiguration\n",
    "# System components\n",
    "from llm.azure_openai import AzureOpenAILLM\n",
    "from embedding.local_embedding import LocalEmbeddingModel\n",
    "from embedding.request_embedding import RequestEmbeddingModel\n",
    "# Prompt\n",
    "from prompt.zero_shot import ZeroShotPrompt\n",
    "from prompt.few_shot import FewShotPrompt\n",
    "from prompt.user_message import UserMessagePrompt\n",
    "from prompt.assistant_message import AssistantMessagePrompt\n",
    "# Memory\n",
    "from base_classes.memory.memory_atom import AbstractMemoryAtom\n",
    "from base_classes.memory.memory_block import AbstractMemoryBlock\n",
    "from base_classes.memory.memory import AbstractMemory\n",
    "from base_classes.memory.datatypes.data_item import PromptDataItem\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s\\t\\t%(levelname)s\\t%(message)s',\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. System component test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. LLM test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Azure OpenAI test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4o_azure_configuration = APILLMConfiguration()\n",
    "gpt_4o_azure_configuration.load(\"configuration/yaml/llm/azure_gpt_4o.yaml\")\n",
    "azure_gpt_4o = AzureOpenAILLM(gpt_4o_azure_configuration)\n",
    "\n",
    "try:\n",
    "    azure_gpt_4o_1 = AzureOpenAILLM(gpt_4o_azure_configuration)\n",
    "except Exception as e:\n",
    "    logging.info(\"LLM unique ID test successful\")\n",
    "    logging.error(f\"Failed to create AzureOpenAILLM instance: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_zero_shot_message = ZeroShotPrompt(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Health check. Say 'hi' to start the conversation.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "sample_zero_shot_message_responses = azure_gpt_4o.query(query=sample_zero_shot_message.prompt, num_responses=2)\n",
    "print(azure_gpt_4o.get_response_texts(sample_zero_shot_message_responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_few_shots_message = FewShotPrompt(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are NetMind assistant. You task is to answer to the user anything about Viettel Group.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Tell me about Viettel Group.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\", \n",
    "            \"content\": \"Viettel Group is a Vietnamese multinational telecommunications company headquartered in Hanoi, Vietnam. It is a state-owned enterprise and operated by the Ministry of Defence. You can find out more about Viettel Group at https://viettel.vn/.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the revenue of Viettel Group?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "sample_few_shots_message_responses = azure_gpt_4o.query(query=sample_few_shots_message.prompt, num_responses=2)\n",
    "print(azure_gpt_4o.get_response_texts(sample_few_shots_message_responses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Embedding test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. Request embedding model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mini_v2_configuration = APIEmbeddingModelConfiguration()\n",
    "all_mini_v2_configuration.load(\"configuration/yaml/embedding/all-MiniLM-L6-v2.yaml\")\n",
    "all_mini_v2 = RequestEmbeddingModel(all_mini_v2_configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mini_v2.encode(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mini_v2 = RequestEmbeddingModel(all_mini_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\"b\": 1, \"c\": 2}\n",
    "list(a.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Tool test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1. Python code runner tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.python_code_runner import PythonCodeRunnerTool\n",
    "from configuration.tool_configuration import ToolConfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_code_runner_config = ToolConfiguration()\n",
    "python_code_runner_config.load(\"configuration/yaml/tools/python_code_runner.yaml\")\n",
    "python_code_runner = PythonCodeRunnerTool(python_code_runner_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_code_list = [\n",
    "    {\n",
    "        \"code_string\": \"a = 11\\nb = 20\\nresult = a + b\\n\\ndef greet(name):\\n return f'Hello, {name}!'\\n \\nmessage = greet('World')\",\n",
    "        \"id\": \"1\"\n",
    "    },\n",
    "    {\n",
    "        \"code_string\": \"def multiply(x, y):\\n\\treturn x * y\\n\\nnum1 = 5\\nnum2 = 3\\nresult = multiply(num1, num2)\\n\\nprint(f'The product of {num1} and {num2} is {result}.')\",\n",
    "        \"id\": \"2\"\n",
    "    }\n",
    "]\n",
    "\n",
    "results = python_code_runner.execute(input_code_list=input_code_list)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Memory test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_data_1 = [{\n",
    "    'role': 'user',\n",
    "    'content': 'Calculate the sum of 11 and 20.'\n",
    "}]\n",
    "mem_atom_1 = AbstractMemoryAtom(data=PromptDataItem(UserMessagePrompt(prompt_data_1)))\n",
    "\n",
    "prompt_data_2 = [{\n",
    "    'role': 'assistant',\n",
    "    'content': 'In order to calculate the sum of two numbers, we need to do the following:\\n\\t1. Write a Python code with add_sum() function, receiving 2 variables.\\n\\t2. Execute the code with the given variables.\\n\\t3. Return the result of the sum.'\n",
    "}]\n",
    "mem_atom_2 = AbstractMemoryAtom(data=PromptDataItem(AssistantMessagePrompt(prompt_data_2)))\n",
    "\n",
    "prompt_data_3 = [{\n",
    "    'role': 'assistant',\n",
    "    'content': 'Here is the Python code to calculate the sum of two numbers:\\n\\na = 11\\nb = 20\\nresult = a + b\\n\\nprint(f\"The sum of {a} and {b} is {result}.\")'\n",
    "}]\n",
    "mem_atom_3 = AbstractMemoryAtom(data=PromptDataItem(AssistantMessagePrompt(prompt_data_3)))\n",
    "\n",
    "prompt_data_4 = [{\n",
    "    'role': 'assistant',\n",
    "    'content': 'After executing the code, we got the sum of 11 and 20 is 31.'\n",
    "}]\n",
    "mem_atom_4 = AbstractMemoryAtom(data=PromptDataItem(AssistantMessagePrompt(prompt_data_4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AbstractMemoryAtom.get_mematom_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_block = AbstractMemoryBlock()\n",
    "mem_block.add_memory_atom(mem_atom_1)\n",
    "mem_block.add_memory_atom(mem_atom_2)\n",
    "mem_block.add_memory_atom(mem_atom_3)\n",
    "mem_block.add_memory_atom(mem_atom_4)\n",
    "\n",
    "mem_block.mem_atom_graph = {\n",
    "        mem_atom_1.mem_atom_id: [mem_atom_2.mem_atom_id],\n",
    "        mem_atom_2.mem_atom_id: [mem_atom_3.mem_atom_id, mem_atom_4.mem_atom_id],\n",
    "        mem_atom_3.mem_atom_id: [],\n",
    "        mem_atom_4.mem_atom_id: []\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = AbstractMemory()\n",
    "memory.add_memory_block(mem_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.get_memory_block_by_id(mem_block.mem_block_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotated_docs.json_schema import as_json_schema\n",
    "\n",
    "class A:\n",
    "    \"\"\"\n",
    "    This is a class A.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, a: int, b: str):\n",
    "        \"\"\"\n",
    "        This is the constructor of class A.\n",
    "        \"\"\"\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "    @classmethod\n",
    "    def get_a(self, m: int) -> int:\n",
    "        \"\"\"\n",
    "        This is the get_a method of class A.\n",
    "        \"\"\"\n",
    "        return self.a\n",
    "    \n",
    "    def get_b(self) -> str:\n",
    "        \"\"\"\n",
    "        This is the get_b method of class A.\n",
    "        \"\"\"\n",
    "        return self.b\n",
    "\n",
    "a = A(a = 2, b = \"a\")\n",
    "\n",
    "as_json_schema(A.get_a)\n",
    "# a = A(a = 2, b = \"a\")\n",
    "# as_json_schema(A.get_a())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from abc import ABC\n",
    "\n",
    "class CustomLogger(logging.Logger):\n",
    "    def __init__(self, name, containing_class_name, level=logging.NOTSET):\n",
    "        super().__init__(name, level)\n",
    "        # Explicitly set logger level to DEBUG to ensure all messages are processed\n",
    "        self.setLevel(logging.DEBUG)\n",
    "        self.containing_class_name = containing_class_name\n",
    "        self.level_formats = {\n",
    "            logging.DEBUG: {\"prefix\": f\"[🔧 {containing_class_name}] \", \"suffix\": \"\"},\n",
    "            logging.INFO: {\"prefix\": f\"[ℹ️ {containing_class_name}] \", \"suffix\": \"\"},\n",
    "            logging.WARNING: {\"prefix\": f\"[⚠️ {containing_class_name}] \", \"suffix\": \"\"},\n",
    "            logging.ERROR: {\"prefix\": f\"[❌ {containing_class_name}] \", \"suffix\": \"\"},\n",
    "            logging.CRITICAL: {\"prefix\": f\"[‼️ {containing_class_name}] \", \"suffix\": \"\"}\n",
    "        }\n",
    "\n",
    "    def _log(self, level, msg, args, exc_info=None, extra=None, stack_info=False, stacklevel=1):\n",
    "        fmt = self.level_formats.get(level, {\"prefix\": f\"[📜 {self.containing_class_name}] \", \"suffix\": \"\"})\n",
    "        modified_msg = f\"{fmt['prefix']}{msg}{fmt['suffix']}\"\n",
    "        super()._log(level, modified_msg, args, exc_info, extra, stack_info, stacklevel)\n",
    "\n",
    "    def debug(self, msg, *args, **kwargs):\n",
    "        self._log(logging.DEBUG, msg, args, **kwargs)\n",
    "\n",
    "    def info(self, msg, *args, **kwargs):\n",
    "        self._log(logging.INFO, msg, args, **kwargs)\n",
    "\n",
    "    def warning(self, msg, *args, **kwargs):\n",
    "        self._log(logging.WARNING, msg, args, **kwargs)\n",
    "\n",
    "    def error(self, msg, *args, **kwargs):\n",
    "        self._log(logging.ERROR, msg, args, **kwargs)\n",
    "\n",
    "    def critical(self, msg, *args, **kwargs):\n",
    "        self._log(logging.CRITICAL, msg, args, **kwargs)\n",
    "\n",
    "class HasLoggerClass(ABC):\n",
    "    logger: CustomLogger\n",
    "\n",
    "    def __init__(self):\n",
    "        # Initialize logger with the class name of the containing class\n",
    "        self.logger = CustomLogger(self.__class__.__name__, self.__class__.__name__)\n",
    "\n",
    "# Example implementation\n",
    "class MyClass(HasLoggerClass):\n",
    "    def do_something(self):\n",
    "        self.logger.warning(\"Warning about something\")\n",
    "        self.logger.error(\"Error in something\")\n",
    "        self.logger.critical(\"Critical issue in something\")\n",
    "        self.logger.debug(\"Debugging something\")\n",
    "        self.logger.info(\"Info about something\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the custom logger class\n",
    "    logging.setLoggerClass(CustomLogger)\n",
    "    \n",
    "    # Configure logging with basicConfig\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s\\t\\t%(levelname)s\\t%(message)s',\n",
    "        handlers=[logging.StreamHandler()]\n",
    "    )\n",
    "    \n",
    "    # Create an instance of MyClass\n",
    "    obj = MyClass()\n",
    "    \n",
    "    # Ensure the logger propagates to the root logger to use basicConfig settings\n",
    "    obj.logger.propagate = True\n",
    "    \n",
    "    # Test the logger\n",
    "    obj.do_something()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
