{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Configurations\n",
    "from configuration.llm_inference_configuration import APILLMConfiguration\n",
    "from configuration.embedding_inference_configuration import APIEmbeddingModelConfiguration, LocalEmbeddingModelConfiguration\n",
    "from configuration.nlp_configuration import NLPConfiguration\n",
    "from configuration.tool_configuration import ToolConfiguration, DemonstrationSamplingToolConfiguration, ToolChooserToolConfiguration\n",
    "from configuration.operator_configuration import CoTOperatorConfiguration, DebateOperatorConfiguration, ReActOperatorConfiguration\n",
    "# System components\n",
    "from llm.request_llm import RequestLLM\n",
    "from embedding.request_embedding import RequestEmbeddingModel\n",
    "from nlp.spacy_nlp import SpacyNLP\n",
    "from tools.python_code_runner import PythonCodeRunnerTool\n",
    "from tools.demonstration_sampling import DemonstrationSamplingTool\n",
    "from tools.tool_chooser import ToolChooserTool\n",
    "# Prompt\n",
    "from prompt.zero_shot import ZeroShotPrompt\n",
    "from prompt.few_shot import FewShotPrompt\n",
    "from prompt.user_message import UserMessagePrompt\n",
    "from prompt.assistant_message import AssistantMessagePrompt\n",
    "from prompt.tool_message import ToolMessagePrompt\n",
    "# Memory\n",
    "from base_classes.memory.memory_atom import AbstractMemoryAtom\n",
    "from base_classes.memory.memory_block import AbstractMemoryBlock\n",
    "from base_classes.memory.memory_topic import AbstractMemoryTopic\n",
    "from base_classes.memory.datatypes.data_item import PromptDataItem\n",
    "from base_classes.memory.memory_worker import MemoryWorker\n",
    "# MCP\n",
    "# from tools.mcp_server\n",
    "# Operator\n",
    "from base_classes.operator import AbstractOperator\n",
    "from operators.cot import CoTOperator\n",
    "from operators.debate import DebateOperator\n",
    "from operators.react import ReactOperator\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s\\t\\t%(levelname)s\\t%(message)s',\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. System component test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. LLM test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Azure OpenAI test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4o_azure_configuration = APILLMConfiguration()\n",
    "gpt_4o_azure_configuration.load(\"configuration/yaml/llm/azure_gpt_4o.yaml\")\n",
    "azure_gpt_4o = RequestLLM(gpt_4o_azure_configuration)\n",
    "\n",
    "try:\n",
    "    azure_gpt_4o_1 = RequestLLM(gpt_4o_azure_configuration)\n",
    "except Exception as e:\n",
    "    logging.info(\"LLM unique ID test successful\")\n",
    "    logging.error(f\"Failed to create AzureOpenAILLM instance: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_zero_shot_message = ZeroShotPrompt(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Write a 1000-word very long report about economic growth in Vietnam\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "sample_zero_shot_message_responses = azure_gpt_4o.query(query=sample_zero_shot_message, num_responses=2)\n",
    "print(azure_gpt_4o.get_response_texts(sample_zero_shot_message_responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_few_shots_message = FewShotPrompt(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are NetMind assistant. You task is to answer to the user anything about Viettel Group.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Tell me about Viettel Group.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\", \n",
    "            \"content\": \"Viettel Group is a Vietnamese multinational telecommunications company headquartered in Hanoi, Vietnam. It is a state-owned enterprise and operated by the Ministry of Defence. You can find out more about Viettel Group at https://viettel.vn/.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the revenue of Viettel Group? Tell me the list of child companies of Viettel Group?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "sample_few_shots_message_responses = azure_gpt_4o.query(query=sample_few_shots_message.prompt, num_responses=2)\n",
    "print(azure_gpt_4o.get_response_texts(sample_few_shots_message_responses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Embedding test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. Request embedding model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embedding_ada_002_config = APIEmbeddingModelConfiguration()\n",
    "text_embedding_ada_002_config.load(\"configuration/yaml/embedding/text-embedding-ada-002.yaml\")\n",
    "text_embedding_ada_002 = RequestEmbeddingModel(text_embedding_ada_002_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_embedding_ada_002.encode(\"Hello world\")\n",
    "text_embedding_ada_002.similarity(\"Hello world\", \"Hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Tool test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1. Python code runner tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_code_runner_config = ToolConfiguration()\n",
    "python_code_runner_config.load(\"configuration/yaml/tools/python_code_runner.yaml\")\n",
    "python_code_runner = PythonCodeRunnerTool(python_code_runner_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_code_list = [\n",
    "    {\n",
    "        \"code_string\": \"a = 11\\nb = 20\\nresult = a + b\\n\\ndef greet(name):\\n return f'Hello, {name}!'\\n \\nmessage = greet('World')\",\n",
    "        \"id\": \"1\"\n",
    "    },\n",
    "    {\n",
    "        \"code_string\": \"def multiply(x, y):\\n\\treturn x * y\\n\\nnum1 = 5\\nnum2 = 3\\nresult = multiply(num1, num2)\\n\\nprint(f'The product of {num1} and {num2} is {result}.')\",\n",
    "        \"id\": \"2\"\n",
    "    }\n",
    "]\n",
    "\n",
    "results = await python_code_runner.execute(input_code_list=input_code_list)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2. Demostration sampling tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demonstration_sampling_tool_config = DemonstrationSamplingToolConfiguration()\n",
    "demonstration_sampling_tool_config.load(\"configuration/yaml/tools/demonstration_sampling.yaml\")\n",
    "demonstration_sampling_tool = DemonstrationSamplingTool(tool_config=demonstration_sampling_tool_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = await demonstration_sampling_tool.execute(input_message=UserMessagePrompt(\n",
    "    prompt = [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Organize a party\"\n",
    "        }\n",
    "    ]\n",
    "))\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. NLP model test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1. SpaCy NLP test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_nlp_config = NLPConfiguration()\n",
    "spacy_nlp_config.load(\"configuration/yaml/nlp/spacy.yaml\")\n",
    "spacy_model = SpacyNLP(spacy_nlp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_model.lemmatize(\"Hello, my name is John Doe. I am a software engineer. I love coding and solving problems.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Memory test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_utils.memory import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory Worker Initiation\n",
    "spacy_nlp_config = NLPConfiguration()\n",
    "spacy_nlp_config.load(\"configuration/yaml/nlp/spacy.yaml\")\n",
    "spacy_model = SpacyNLP(spacy_nlp_config)\n",
    "\n",
    "gpt_4o_azure_configuration = APILLMConfiguration()\n",
    "gpt_4o_azure_configuration.load(\"configuration/yaml/llm/azure_gpt_4o.yaml\")\n",
    "azure_gpt_4o = RequestLLM(gpt_4o_azure_configuration)\n",
    "\n",
    "text_embedding_ada_002_config = APIEmbeddingModelConfiguration()\n",
    "text_embedding_ada_002_config.load(\"configuration/yaml/embedding/text-embedding-ada-002.yaml\")\n",
    "text_embedding_ada_002 = RequestEmbeddingModel(text_embedding_ada_002_config)\n",
    "\n",
    "memory_worker = MemoryWorker(\n",
    "    emb_model=text_embedding_ada_002,\n",
    "    llm=azure_gpt_4o,\n",
    "    nlp_model=spacy_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_worker.feature_engineer_for_memory_block(mem_block_1)\n",
    "memory_worker.feature_engineer_for_memory_block(mem_block_2)\n",
    "memory_worker.feature_engineer_for_memory_block(mem_block_3)\n",
    "memory_worker.feature_engineer_for_memory_block(mem_block_4)\n",
    "memory_worker.feature_engineer_for_memory_block(mem_block_5)\n",
    "memory_worker.feature_engineer_for_memory_block(mem_block_6)\n",
    "\n",
    "memory_worker.feature_engineer_for_memory_topic(mem_topic_1)\n",
    "memory_worker.feature_engineer_for_memory_topic(mem_topic_2)\n",
    "memory_worker.feature_engineer_for_memory_topic(mem_topic_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_query = [{\n",
    "    'role': 'user',\n",
    "    'content': 'I have a problem with my integer_adder() program. It can not output the sum of numbers given to it. Can you calculate the sum of integers from 1 to 100?'\n",
    "}]\n",
    "new_mem_atom = AbstractMemoryAtom(data=PromptDataItem(UserMessagePrompt(new_query)))\n",
    "\n",
    "new_mem_block = AbstractMemoryBlock()\n",
    "new_mem_block.add_memory_atom(new_mem_atom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_topics = memory_worker.select_relevant_topics(new_mem_block, mem_stack, top_n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mtp, scr in relevant_topics:\n",
    "    mtp.add_mem_block(new_mem_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_mem_blocks = memory_worker.memory_block_retrieval(new_mem_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(retrieved_mem_blocks[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4o_azure_configuration = APILLMConfiguration()\n",
    "gpt_4o_azure_configuration.load(\"configuration/yaml/llm/azure_gpt_4o.yaml\")\n",
    "azure_gpt_4o = RequestLLM(gpt_4o_azure_configuration)\n",
    "\n",
    "demonstration_sampling_tool_config = DemonstrationSamplingToolConfiguration()\n",
    "demonstration_sampling_tool_config.load(\"configuration/yaml/tools/demonstration_sampling.yaml\")\n",
    "demonstration_sampling_tool = DemonstrationSamplingTool(tool_config=demonstration_sampling_tool_config)\n",
    "\n",
    "cot_operator_config = CoTOperatorConfiguration()\n",
    "cot_operator_config.load(\"configuration/yaml/operators/cot.yaml\")\n",
    "cot_operator = CoTOperator(config=cot_operator_config)\n",
    "\n",
    "all_logger_names = list(logging.root.manager.loggerDict.keys())\n",
    "if '' not in all_logger_names:\n",
    "    all_logger_names.append('')\n",
    "\n",
    "for logger_name in all_logger_names:\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    if logger_name.startswith(\"Orbit\"):\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "    elif logger_name == '':\n",
    "        logger.setLevel(logging.CRITICAL)\n",
    "    else:\n",
    "        logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_test_message = UserMessagePrompt(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Organize a party\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "cot_test_answer, cot_test_dependency_graph = await cot_operator.run(input_message=cot_test_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Debate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4o_azure_configuration = APILLMConfiguration()\n",
    "gpt_4o_azure_configuration.load(\"configuration/yaml/llm/azure_gpt_4o.yaml\")\n",
    "azure_gpt_4o = RequestLLM(gpt_4o_azure_configuration)\n",
    "\n",
    "debate_operator_config = DebateOperatorConfiguration()\n",
    "debate_operator_config.load(\"configuration/yaml/operators/debate.yaml\")\n",
    "debate_operator = DebateOperator(debate_operator_config)\n",
    "\n",
    "all_logger_names = list(logging.root.manager.loggerDict.keys())\n",
    "if '' not in all_logger_names:\n",
    "    all_logger_names.append('')\n",
    "\n",
    "for logger_name in all_logger_names:\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    if logger_name.startswith(\"Orbit\"):\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "    elif logger_name == '':\n",
    "        logger.setLevel(logging.CRITICAL)\n",
    "    else:\n",
    "        logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debate_test_message = AssistantMessagePrompt(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"What is the capital of Vietnam? Then give me some information about this city (only 3 adjectives on 1 line). Make sure that these 3 adjectives represent the most notable information about this city. Then give e a random number between 1 and 100.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "debate_test_answer, debate_test_dependency_graph = await debate_operator.run(input_message=debate_test_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debate_test_dependency_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from base_classes.memory.memory_atom import AbstractMemoryAtom\n",
    "\n",
    "print(AbstractMemoryAtom.get_mematom_instance_by_id(uuid.UUID(\"8b1fa78d-0614-4c05-bd0d-7cee0681bcb8\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base_classes.memory.memory_atom import AbstractMemoryAtom\n",
    "\n",
    "print(len(AbstractMemoryAtom.get_mematom_ids()))\n",
    "\n",
    "for mem_atom_id in AbstractMemoryAtom.get_mematom_ids():\n",
    "    mem_atom = AbstractMemoryAtom.get_mematom_instance_by_id(mem_atom_id)\n",
    "    print(mem_atom)\n",
    "    print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4o_azure_configuration = APILLMConfiguration()\n",
    "gpt_4o_azure_configuration.load(\"configuration/yaml/llm/azure_gpt_4o.yaml\")\n",
    "azure_gpt_4o = RequestLLM(gpt_4o_azure_configuration)\n",
    "\n",
    "text_embedding_ada_002_config = APIEmbeddingModelConfiguration()\n",
    "text_embedding_ada_002_config.load(\"configuration/yaml/embedding/text-embedding-ada-002.yaml\")\n",
    "text_embedding_ada_002 = RequestEmbeddingModel(text_embedding_ada_002_config)\n",
    "\n",
    "tool_chooser_tool_config = ToolChooserToolConfiguration()\n",
    "tool_chooser_tool_config.load(\"configuration/yaml/tools/tool_chooser.yaml\")\n",
    "tool_chooser_tool = ToolChooserTool(tool_chooser_tool_config)\n",
    "\n",
    "react_operator_config = ReActOperatorConfiguration()\n",
    "react_operator_config.load(\"configuration/yaml/operators/react.yaml\")\n",
    "react_operator = ReactOperator(react_operator_config)\n",
    "\n",
    "all_logger_names = list(logging.root.manager.loggerDict.keys())\n",
    "if '' not in all_logger_names:\n",
    "    all_logger_names.append('')\n",
    "\n",
    "for logger_name in all_logger_names:\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    if logger_name.startswith(\"Orbit\"):\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "    elif logger_name == '':\n",
    "        logger.setLevel(logging.CRITICAL)\n",
    "    else:\n",
    "        logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_workflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
