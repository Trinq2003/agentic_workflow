{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\miniconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Configurations\n",
    "from configuration.llm_inference_configuration import APILLMConfiguration\n",
    "from configuration.embedding_inference_configuration import APIEmbeddingModelConfiguration, LocalEmbeddingModelConfiguration\n",
    "# System components\n",
    "from llm.azure_openai import AzureOpenAILLM\n",
    "from embedding.local_embedding import LocalEmbeddingModel\n",
    "from embedding.request_embedding import RequestEmbeddingModel\n",
    "# Prompt\n",
    "from prompt.zero_shot import ZeroShotPrompt\n",
    "from prompt.few_shot import FewShotPrompt\n",
    "from prompt.user_message import UserMessagePrompt\n",
    "from prompt.assistant_message import AssistantMessagePrompt\n",
    "# Memory\n",
    "from base_classes.memory.memory_atom import AbstractMemoryAtom\n",
    "from base_classes.memory.memory_block import AbstractMemoryBlock\n",
    "from base_classes.memory.memory import AbstractMemory\n",
    "from base_classes.memory.datatypes.data_item import PromptDataItem\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s\\t\\t%(levelname)s\\t%(message)s',\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. System component test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. LLM test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Azure OpenAI test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4o_azure_configuration = APILLMConfiguration()\n",
    "gpt_4o_azure_configuration.load(\"configuration/yaml/llm/azure_gpt_4o.yaml\")\n",
    "azure_gpt_4o = AzureOpenAILLM(gpt_4o_azure_configuration)\n",
    "\n",
    "try:\n",
    "    azure_gpt_4o_1 = AzureOpenAILLM(gpt_4o_azure_configuration)\n",
    "except Exception as e:\n",
    "    logging.info(\"LLM unique ID test successful\")\n",
    "    logging.error(f\"Failed to create AzureOpenAILLM instance: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_zero_shot_message = ZeroShotPrompt(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Health check. Say 'hi' to start the conversation.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "sample_zero_shot_message_responses = azure_gpt_4o.query(query=sample_zero_shot_message.prompt, num_responses=2)\n",
    "print(azure_gpt_4o.get_response_texts(sample_zero_shot_message_responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_few_shots_message = FewShotPrompt(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are NetMind assistant. You task is to answer to the user anything about Viettel Group.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Tell me about Viettel Group.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\", \n",
    "            \"content\": \"Viettel Group is a Vietnamese multinational telecommunications company headquartered in Hanoi, Vietnam. It is a state-owned enterprise and operated by the Ministry of Defence. You can find out more about Viettel Group at https://viettel.vn/.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the revenue of Viettel Group?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "sample_few_shots_message_responses = azure_gpt_4o.query(query=sample_few_shots_message.prompt, num_responses=2)\n",
    "print(azure_gpt_4o.get_response_texts(sample_few_shots_message_responses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Embedding test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. Request embedding model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mini_v2_configuration = APIEmbeddingModelConfiguration()\n",
    "all_mini_v2_configuration.load(\"configuration/yaml/embedding/all-MiniLM-L6-v2.yaml\")\n",
    "all_mini_v2 = RequestEmbeddingModel(all_mini_v2_configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mini_v2.encode(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mini_v2 = RequestEmbeddingModel(all_mini_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\"b\": 1, \"c\": 2}\n",
    "list(a.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Tool test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1. Python code runner tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.python_code_runner import PythonCodeRunnerTool\n",
    "from configuration.tool_configuration import ToolConfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_code_runner_config = ToolConfiguration()\n",
    "python_code_runner_config.load(\"configuration/yaml/tools/python_code_runner.yaml\")\n",
    "python_code_runner = PythonCodeRunnerTool(python_code_runner_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_code_list = [\n",
    "    {\n",
    "        \"code_string\": \"a = 11\\nb = 20\\nresult = a + b\\n\\ndef greet(name):\\n return f'Hello, {name}!'\\n \\nmessage = greet('World')\",\n",
    "        \"id\": \"1\"\n",
    "    },\n",
    "    {\n",
    "        \"code_string\": \"def multiply(x, y):\\n\\treturn x * y\\n\\nnum1 = 5\\nnum2 = 3\\nresult = multiply(num1, num2)\\n\\nprint(f'The product of {num1} and {num2} is {result}.')\",\n",
    "        \"id\": \"2\"\n",
    "    }\n",
    "]\n",
    "\n",
    "results = python_code_runner.execute(input_code_list=input_code_list)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Memory test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 22:37:46,424\t\tDEBUG\t[ðŸ”§UserMessagePrompt] Prompt initialized with 1 messages.\n",
      "2025-05-09 22:37:46,425\t\tDEBUG\t[ðŸ”§AbstractMemoryAtom] Memory Atom ID: 46f336de-4c73-4085-9fe0-9154b570f5fa | Memory Atom type: 1; Memory Atom state: 1\n",
      "2025-05-09 22:37:46,425\t\tDEBUG\t[ðŸ”§AssistantMessagePrompt] Prompt initialized with 1 messages.\n",
      "2025-05-09 22:37:46,426\t\tDEBUG\t[ðŸ”§AbstractMemoryAtom] Memory Atom ID: 6cda2851-cd31-465c-bfa4-dece42bb34ba | Memory Atom type: 2; Memory Atom state: 1\n",
      "2025-05-09 22:37:46,427\t\tDEBUG\t[ðŸ”§AssistantMessagePrompt] Prompt initialized with 1 messages.\n",
      "2025-05-09 22:37:46,427\t\tDEBUG\t[ðŸ”§AbstractMemoryAtom] Memory Atom ID: 2000dd58-a77c-4ae6-9440-6a09a4b33586 | Memory Atom type: 2; Memory Atom state: 1\n",
      "2025-05-09 22:37:46,428\t\tDEBUG\t[ðŸ”§AssistantMessagePrompt] Prompt initialized with 1 messages.\n",
      "2025-05-09 22:37:46,428\t\tDEBUG\t[ðŸ”§AbstractMemoryAtom] Memory Atom ID: c3afd6d3-dbd4-464a-ae02-e9747d5881d0 | Memory Atom type: 2; Memory Atom state: 1\n"
     ]
    }
   ],
   "source": [
    "prompt_data_1 = [{\n",
    "    'role': 'user',\n",
    "    'content': 'Calculate the sum of 11 and 20.'\n",
    "}]\n",
    "mem_atom_1 = AbstractMemoryAtom(data=PromptDataItem(UserMessagePrompt(prompt_data_1)))\n",
    "\n",
    "prompt_data_2 = [{\n",
    "    'role': 'assistant',\n",
    "    'content': 'In order to calculate the sum of two numbers, we need to do the following:\\n\\t1. Write a Python code with add_sum() function, receiving 2 variables.\\n\\t2. Execute the code with the given variables.\\n\\t3. Return the result of the sum.'\n",
    "}]\n",
    "mem_atom_2 = AbstractMemoryAtom(data=PromptDataItem(AssistantMessagePrompt(prompt_data_2)))\n",
    "\n",
    "prompt_data_3 = [{\n",
    "    'role': 'assistant',\n",
    "    'content': 'Here is the Python code to calculate the sum of two numbers:\\n\\na = 11\\nb = 20\\nresult = a + b\\n\\nprint(f\"The sum of {a} and {b} is {result}.\")'\n",
    "}]\n",
    "mem_atom_3 = AbstractMemoryAtom(data=PromptDataItem(AssistantMessagePrompt(prompt_data_3)))\n",
    "\n",
    "prompt_data_4 = [{\n",
    "    'role': 'assistant',\n",
    "    'content': 'After executing the code, we got the sum of 11 and 20 is 31.'\n",
    "}]\n",
    "mem_atom_4 = AbstractMemoryAtom(data=PromptDataItem(AssistantMessagePrompt(prompt_data_4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 22:37:51,939\t\tDEBUG\t[ðŸ”§AbstractMemoryBlock] Memory Block ID: 8b149d68-854a-4ebb-b658-c460aa1bf775 | Memory Block state: 1\n",
      "2025-05-09 22:37:51,940\t\tDEBUG\t[ðŸ”§AbstractMemoryBlock] Memory Block ID: 8b149d68-854a-4ebb-b658-c460aa1bf775 | Memory Block state: 2\n",
      "2025-05-09 22:37:51,940\t\tDEBUG\t[ðŸ”§AbstractMemoryBlock] Memory Block ID: 8b149d68-854a-4ebb-b658-c460aa1bf775 | Memory Block state: 2\n",
      "2025-05-09 22:37:51,941\t\tDEBUG\t[ðŸ”§AbstractMemoryBlock] Memory Block ID: 8b149d68-854a-4ebb-b658-c460aa1bf775 | Memory Block state: 2\n"
     ]
    }
   ],
   "source": [
    "mem_block = AbstractMemoryBlock()\n",
    "mem_block.add_memory_atom(mem_atom_1)\n",
    "mem_block.add_memory_atom(mem_atom_2)\n",
    "mem_block.add_memory_atom(mem_atom_3)\n",
    "mem_block.add_memory_atom(mem_atom_4)\n",
    "\n",
    "mem_block.mem_atom_graph = {\n",
    "        mem_atom_1.mem_atom_id: [mem_atom_2.mem_atom_id],\n",
    "        mem_atom_2.mem_atom_id: [mem_atom_3.mem_atom_id, mem_atom_4.mem_atom_id],\n",
    "        mem_atom_3.mem_atom_id: [],\n",
    "        mem_atom_4.mem_atom_id: []\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 22:38:02,334\t\tDEBUG\tMemory block: 8b149d68-854a-4ebb-b658-c460aa1bf775\n",
      "2025-05-09 22:38:02,335\t\tDEBUG\tConteiner toppic: None\n",
      "2025-05-09 22:38:02,335\t\tDEBUG\tMemory block state: 2\n"
     ]
    }
   ],
   "source": [
    "logging.debug(f\"Memory block: {mem_block.mem_block_id}\")\n",
    "logging.debug(f\"Conteiner toppic: {mem_block.topic_container_id}\")\n",
    "logging.debug(f\"Memory block state: {mem_block.mem_block_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
